{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define API key and base URL\n",
    "api_key = \"FDyVl7GLwOsIvkhy4fp1v3oEpCxHyyPp\"\n",
    "base_url_open_close = \"https://api.polygon.io/v1/open-close\"\n",
    "base_url_financials = \"https://api.polygon.io/vX/reference/financials\"\n",
    "\n",
    "# Read the existing CSV file to determine the last date\n",
    "existing_file_path = r\"C:\\Users\\SamuliMustonen\\Documents\\Ready Solutions\\Docs\\StockTrading\\Data\\ntnx_data_raw.csv\"\n",
    "existing_data = pd.read_csv(existing_file_path, delimiter=';', header=0)\n",
    "\n",
    "# Ensure the 'Date' column is in datetime format and get the last date\n",
    "existing_data['Date'] = pd.to_datetime(existing_data['Date'])\n",
    "\n",
    "# Define ticker and date range\n",
    "ticker = \"NTNX\"\n",
    "start_date = \"2022-10-18\"\n",
    "end_date = \"2022-12-31\"\n",
    "\n",
    "# Convert date strings to datetime objects\n",
    "start = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "end = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "\n",
    "# Initialize an empty list to hold all stock data\n",
    "all_stock_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize API call counter\n",
    "api_call_count = 0\n",
    "# Function to handle API call rate limit\n",
    "def check_rate_limit():\n",
    "    global api_call_count\n",
    "    api_call_count += 1\n",
    "    if api_call_count == 5:\n",
    "        print(\"Pausing for 1 minute to respect API rate limit...\")\n",
    "        time.sleep(60)  # Pause for 1 minute\n",
    "        api_call_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch open/close data for a specific ticker and date\n",
    "def fetch_stock_data(ticker, date):\n",
    "    url = f\"{base_url_open_close}/{ticker}/{date}\"\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if data.get(\"status\") == \"OK\":\n",
    "            stock_data = {\n",
    "                \"Symbol\": data.get(\"symbol\"),\n",
    "                \"Date\": data.get(\"from\"),\n",
    "                \"Close\": data.get(\"close\"),\n",
    "                \"Open\": data.get(\"open\"),\n",
    "                \"High\": data.get(\"high\"),\n",
    "                \"Low\": data.get(\"low\"),\n",
    "                \"Volume\": data.get(\"volume\")\n",
    "            }\n",
    "            return stock_data\n",
    "        else:\n",
    "            print(f\"No trading data for {ticker} on {date}.\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Failed to fetch data for {ticker} on {date}: {response.status_code}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch financial report filing dates\n",
    "def fetch_filing_dates(ticker):\n",
    "    filing_dates = set()\n",
    "    url = f\"{base_url_financials}?ticker={ticker}&limit=100&apiKey={api_key}\"\n",
    "    \n",
    "    while url:\n",
    "        response = requests.get(url)\n",
    "        check_rate_limit()  # Check and handle API rate limit\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            for item in data.get('results', []):\n",
    "                filing_date = item.get('filing_date')\n",
    "                if filing_date:\n",
    "                    filing_dates.add(filing_date)  # Collect filing dates\n",
    "                    \n",
    "            url = data.get('next_url')  # Check if there's a next page to fetch\n",
    "        else:\n",
    "            print(f\"Failed to fetch financial data for {ticker}: {response.status_code}\")\n",
    "            url = None  # Stop the loop if there's an error\n",
    "\n",
    "    return filing_dates\n",
    "\n",
    "\n",
    "# Fetch financial report filing dates\n",
    "filing_dates = fetch_filing_dates(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over each date in the range\n",
    "current_date = start\n",
    "api_call_count = 0\n",
    "\n",
    "while current_date <= end:\n",
    "    date_str = current_date.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    # Fetch stock data for the current date\n",
    "    stock_data = fetch_stock_data(ticker, date_str)\n",
    "    check_rate_limit()\n",
    "    \n",
    "    if stock_data:\n",
    "        # Check if a financial report was released on this date\n",
    "        stock_data[\"financialRelease\"] = 1 if date_str in filing_dates else 0\n",
    "        \n",
    "        all_stock_data.append(stock_data)\n",
    "\n",
    "    # Increment API call count\n",
    "    api_call_count += 1\n",
    "\n",
    "    # After every 5 API calls, pause for 1 minute to respect the API limit\n",
    "    # if api_call_count == 5:\n",
    "    #     print(\"Pausing for 1 minute to respect API rate limit...\")\n",
    "    #     time.sleep(60)\n",
    "    #     api_call_count = 0\n",
    "\n",
    "    # Move to the next date\n",
    "    current_date += timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the collected data\n",
    "df = pd.DataFrame(all_stock_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output path for the CSV file\n",
    "# file_name = '_data'\n",
    "# output_path = r\"C:\\Users\\SamuliMustonen\\Documents\\Ready Solutions\\Docs\\StockTrading\\Data\\{file_name}.csv\"\n",
    "\n",
    "# Append the DataFrame to the existing CSV file, avoiding duplicates\n",
    "if not df.empty:\n",
    "    df.to_csv(existing_file_path, mode='a', index=False, header=False, sep=';')\n",
    "\n",
    "print(f\"Data has been appended to {existing_file_path}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding parameters to the data model\n",
    "**ema20** = exponential moving average 20 days.\n",
    "**ema50** = exponential moving average 50 days.\n",
    "**openHigher** = If Open > (1,01 * Previous day Close) then 1 else 0.\n",
    "**strongClose** = function=(High + Low) / 2. If Close > 'function' then 1 else 0.\n",
    "**averageVolume** = Average volume from past 200 days. 200 simple moving average for volume.\n",
    "**strongVolume** = If Volume > (2 * averageVolume) then 1 else 0.\n",
    "**strongVolume6MoPrior** = If strongVolume is equal to 1 more than 3 times in the past 126 days then 1 else 0.\n",
    "**strongVolumeAfterFiling** = If strongVolume is equal to 1 more 2 times in the following 5 days after financialRelease = 1 then 1 else 0.\n",
    "**accVolume** = If strongVolume = 1 and strongVolume6MoPrior = 1 and strongVolumeAfterFiling = 1 then 1 else 0.\n",
    "**uptrend** = If ema50 > (ema50 50 days prior) then 1 else 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to your existing CSV file\n",
    "csv_file_path = r\"C:\\Users\\SamuliMustonen\\Documents\\Ready Solutions\\Docs\\StockTrading\\Data\\ntnx_data_raw.csv\"\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_file_path, delimiter=';', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to your existing CSV file\n",
    "csv_file_path = r\"C:\\Users\\SamuliMustonen\\Documents\\Ready Solutions\\Docs\\StockTrading\\Data\\ntnx_data_raw.csv\"\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_file_path, delimiter=';', header=0)\n",
    "\n",
    "# Function to calculate EMA\n",
    "def calculate_ema(data, window):\n",
    "    \"\"\"Calculate the Exponential Moving Average (EMA) for a given window.\"\"\"\n",
    "    # Calculate EMA using ewm() and handle insufficient data gracefully\n",
    "    ema = data['Close'].ewm(span=window, adjust=False).mean()\n",
    "    \n",
    "    # Replace initial values with NaN for insufficient data\n",
    "    if len(data) < window:\n",
    "        ema[:window] = None  # Set initial window values to None (NaN)\n",
    "    \n",
    "    return ema\n",
    "\n",
    "# Calculate EMA20 and EMA50\n",
    "df['ema20'] = calculate_ema(df, 20)\n",
    "df['ema50'] = calculate_ema(df, 50)\n",
    "# Round ema20 and ema50 to 2 decimal places\n",
    "df['ema20'] = df['ema20'].round(2)\n",
    "df['ema50'] = df['ema50'].round(2)\n",
    "\n",
    "# **openHigher** = If Open > (1.01 * Previous day Close) then 1 else 0\n",
    "df['openHigher'] = (df['Open'] > (1.01 * df['Close'].shift(1))).astype(int)\n",
    "\n",
    "# **strongClose** = (High + Low) / 2. If Close > 'function' then 1 else 0\n",
    "df['function'] = (df['High'] + df['Low']) / 2\n",
    "df['strongClose'] = (df['Close'] > df['function']).astype(int)\n",
    "\n",
    "# Convert Volume to integer format\n",
    "df['Volume'] = df['Volume'].astype(int)  # Convert volume to integer\n",
    "\n",
    "# **averageVolume** = Average volume from past 200 days (SMA for volume)\n",
    "df['averageVolume'] = df['Volume'].rolling(window=200).mean()\n",
    "\n",
    "# **strongVolume** = If Volume > (2 * averageVolume) then 1 else 0\n",
    "df['strongVolume'] = (df['Volume'] > 2 * df['averageVolume']).astype(int)\n",
    "\n",
    "# **strongVolume6MoPrior** = If strongVolume is 1 more than 3 times in the past 126 days then 1 else 0\n",
    "df['strongVolume6MoPrior'] = df['strongVolume'].rolling(window=126).sum().shift(1)\n",
    "df['strongVolume6MoPrior'] = (df['strongVolume6MoPrior'] > 3).astype(int)\n",
    "\n",
    "# **strongVolumeAfterFiling** = If strongVolume is 1 more than 2 times in the 5 days after financialRelease = 1 then 1 else 0\n",
    "df['strongVolumeAfterFiling'] = 0\n",
    "for i in range(len(df) - 5):\n",
    "    if df.loc[i, 'financialRelease'] == 1:\n",
    "        if df.loc[i+1:i+5, 'strongVolume'].sum() > 2:\n",
    "            df.loc[i+1:i+5, 'strongVolumeAfterFiling'] = 1\n",
    "\n",
    "# **accVolume** = If strongVolume = 1, strongVolume6MoPrior = 1, and strongVolumeAfterFiling = 1 then 1 else 0\n",
    "df['accVolume'] = ((df['strongVolume'] == 1) & \n",
    "                   (df['strongVolume6MoPrior'] == 1) & \n",
    "                   (df['strongVolumeAfterFiling'] == 1)).astype(int)\n",
    "\n",
    "# **uptrend** = If ema50 > (ema50 50 days prior) then 1 else 0\n",
    "df['uptrend'] = (df['ema50'] > df['ema50'].shift(50)).astype(int)\n",
    "\n",
    "# Drop the 'function' column as it's intermediate\n",
    "df.drop(columns=['function'], inplace=True)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file with a timestamp\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "new_csv_file_path = f\"C:/Users/SamuliMustonen/Documents/Ready Solutions/Docs/StockTrading/Data/ntnx_data_model_{timestamp}.csv\"\n",
    "df.to_csv(new_csv_file_path, index=False)\n",
    "\n",
    "print(f\"Updated data with new columns saved to {new_csv_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
