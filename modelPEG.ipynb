{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch data for NTNX on 2023-01-15: 404\n",
      "Failed to fetch data for NTNX on 2023-01-16: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-01-21: 404\n",
      "Failed to fetch data for NTNX on 2023-01-22: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-01-28: 404\n",
      "Failed to fetch data for NTNX on 2023-01-29: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-02-04: 404\n",
      "Failed to fetch data for NTNX on 2023-02-05: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-02-11: 404\n",
      "Failed to fetch data for NTNX on 2023-02-12: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-02-18: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-02-19: 404\n",
      "Failed to fetch data for NTNX on 2023-02-20: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-02-25: 404\n",
      "Failed to fetch data for NTNX on 2023-02-26: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-03-04: 404\n",
      "Failed to fetch data for NTNX on 2023-03-05: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-03-11: 404\n",
      "Failed to fetch data for NTNX on 2023-03-12: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-03-18: 404\n",
      "Failed to fetch data for NTNX on 2023-03-19: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-03-25: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-03-26: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-04-01: 404\n",
      "Failed to fetch data for NTNX on 2023-04-02: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-04-07: 404\n",
      "Failed to fetch data for NTNX on 2023-04-08: 404\n",
      "Failed to fetch data for NTNX on 2023-04-09: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-04-15: 404\n",
      "Failed to fetch data for NTNX on 2023-04-16: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-04-22: 404\n",
      "Failed to fetch data for NTNX on 2023-04-23: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-04-29: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-04-30: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-05-06: 404\n",
      "Failed to fetch data for NTNX on 2023-05-07: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-05-13: 404\n",
      "Failed to fetch data for NTNX on 2023-05-14: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-05-20: 404\n",
      "Failed to fetch data for NTNX on 2023-05-21: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-05-27: 404\n",
      "Failed to fetch data for NTNX on 2023-05-28: 404\n",
      "Failed to fetch data for NTNX on 2023-05-29: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-06-03: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-06-04: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-06-10: 404\n",
      "Failed to fetch data for NTNX on 2023-06-11: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-06-17: 404\n",
      "Failed to fetch data for NTNX on 2023-06-18: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-06-19: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-06-24: 404\n",
      "Failed to fetch data for NTNX on 2023-06-25: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-07-01: 404\n",
      "Failed to fetch data for NTNX on 2023-07-02: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-07-04: 404\n",
      "Failed to fetch data for NTNX on 2023-07-08: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-07-09: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-07-15: 404\n",
      "Failed to fetch data for NTNX on 2023-07-16: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-07-22: 404\n",
      "Failed to fetch data for NTNX on 2023-07-23: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-07-29: 404\n",
      "Failed to fetch data for NTNX on 2023-07-30: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-08-05: 404\n",
      "Failed to fetch data for NTNX on 2023-08-06: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-08-12: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-08-13: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-08-19: 404\n",
      "Failed to fetch data for NTNX on 2023-08-20: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-08-26: 404\n",
      "Failed to fetch data for NTNX on 2023-08-27: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-09-02: 404\n",
      "Failed to fetch data for NTNX on 2023-09-03: 404\n",
      "Failed to fetch data for NTNX on 2023-09-04: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-09-09: 404\n",
      "Failed to fetch data for NTNX on 2023-09-10: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-09-16: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-09-17: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-09-23: 404\n",
      "Failed to fetch data for NTNX on 2023-09-24: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-09-30: 404\n",
      "Failed to fetch data for NTNX on 2023-10-01: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-10-07: 404\n",
      "Failed to fetch data for NTNX on 2023-10-08: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-10-14: 404\n",
      "Failed to fetch data for NTNX on 2023-10-15: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-10-21: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-10-22: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-10-28: 404\n",
      "Failed to fetch data for NTNX on 2023-10-29: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-11-04: 404\n",
      "Failed to fetch data for NTNX on 2023-11-05: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-11-11: 404\n",
      "Failed to fetch data for NTNX on 2023-11-12: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-11-18: 404\n",
      "Failed to fetch data for NTNX on 2023-11-19: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-11-23: 404\n",
      "Failed to fetch data for NTNX on 2023-11-25: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-11-26: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-12-02: 404\n",
      "Failed to fetch data for NTNX on 2023-12-03: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-12-09: 404\n",
      "Failed to fetch data for NTNX on 2023-12-10: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-12-16: 404\n",
      "Failed to fetch data for NTNX on 2023-12-17: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-12-23: 404\n",
      "Failed to fetch data for NTNX on 2023-12-24: 404\n",
      "Failed to fetch data for NTNX on 2023-12-25: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-12-30: 404\n",
      "Pausing for 1 minute to respect API rate limit...\n",
      "Failed to fetch data for NTNX on 2023-12-31: 404\n",
      "    Symbol        Date  Close    Open     High      Low     Volume\n",
      "0     NTNX  2023-01-17  26.62  26.352  27.0300  26.1504  1860263.0\n",
      "1     NTNX  2023-01-18  26.67  27.040  27.1200  26.4750  1267935.0\n",
      "2     NTNX  2023-01-19  26.26  26.270  26.6100  26.2100  1415566.0\n",
      "3     NTNX  2023-01-20  26.80  26.500  26.8700  26.4800  1432418.0\n",
      "4     NTNX  2023-01-23  28.55  26.940  28.5700  26.6900  1775542.0\n",
      "..     ...         ...    ...     ...      ...      ...        ...\n",
      "236   NTNX  2023-12-22  47.24  46.760  47.4793  46.6860  2424760.0\n",
      "237   NTNX  2023-12-26  47.23  47.330  47.4000  47.0000   897830.0\n",
      "238   NTNX  2023-12-27  47.21  47.190  47.4700  46.9100   771839.0\n",
      "239   NTNX  2023-12-28  47.64  47.100  47.7050  46.9700  1052934.0\n",
      "240   NTNX  2023-12-29  47.69  47.460  47.8300  47.2900  1302880.0\n",
      "\n",
      "[241 rows x 7 columns]\n",
      "Data has been appended to C:\\Users\\SamuliMustonen\\Documents\\Ready Solutions\\Docs\\StockTrading\\Data\\ntnx_data.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "# Define API key and base URL\n",
    "api_key = \"FDyVl7GLwOsIvkhy4fp1v3oEpCxHyyPp\"\n",
    "base_url = \"https://api.polygon.io/v1/open-close\"\n",
    "\n",
    "# Define ticker and date range\n",
    "ticker = \"NTNX\"\n",
    "start_date = \"2023-01-15\"\n",
    "end_date = \"2023-12-31\"\n",
    "\n",
    "# Convert date strings to datetime objects\n",
    "start = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "end = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "\n",
    "# Initialize an empty list to hold all stock data\n",
    "all_stock_data = []\n",
    "\n",
    "# Function to fetch data for a specific ticker and date\n",
    "def fetch_stock_data(ticker, date):\n",
    "    url = f\"{base_url}/{ticker}/{date}\"\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        # Ensure data is present and not empty for non-trading days\n",
    "        if data.get(\"status\") == \"OK\":\n",
    "            # Extract the required fields and return the stock data\n",
    "            stock_data = {\n",
    "                \"Symbol\": data.get(\"symbol\"),\n",
    "                \"Date\": data.get(\"from\"),\n",
    "                \"Close\": data.get(\"close\"),\n",
    "                \"Open\": data.get(\"open\"),\n",
    "                \"High\": data.get(\"high\"),\n",
    "                \"Low\": data.get(\"low\"),\n",
    "                \"Volume\": data.get(\"volume\")\n",
    "            }\n",
    "            return stock_data\n",
    "        else:\n",
    "            print(f\"No trading data for {ticker} on {date}.\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Failed to fetch data for {ticker} on {date}: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Loop over each date in the range\n",
    "current_date = start\n",
    "api_call_count = 0\n",
    "\n",
    "while current_date <= end:\n",
    "    date_str = current_date.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    # Fetch stock data for the current date\n",
    "    stock_data = fetch_stock_data(ticker, date_str)\n",
    "    if stock_data:\n",
    "        all_stock_data.append(stock_data)\n",
    "\n",
    "    # Increment API call count\n",
    "    api_call_count += 1\n",
    "\n",
    "    # After every 5 API calls, pause for 1 minute to respect the API limit\n",
    "    if api_call_count == 5:\n",
    "        print(\"Pausing for 1 minute to respect API rate limit...\")\n",
    "        time.sleep(60)  # Pause for 60 seconds\n",
    "        api_call_count = 0  # Reset the call count\n",
    "\n",
    "    # Move to the next date\n",
    "    current_date += timedelta(days=1)\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "df = pd.DataFrame(all_stock_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Define the output path for the CSV file\n",
    "output_path = r\"C:\\Users\\SamuliMustonen\\Documents\\Ready Solutions\\Docs\\StockTrading\\Data\\ntnx_data.csv\"\n",
    "\n",
    "# Append the DataFrame to the existing CSV file\n",
    "df.to_csv(output_path, mode='a', index=False, header=False)\n",
    "\n",
    "print(f\"Data has been appended to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define API key and base URL\n",
    "api_key = \"FDyVl7GLwOsIvkhy4fp1v3oEpCxHyyPp\"\n",
    "base_url_open_close = \"https://api.polygon.io/v1/open-close\"\n",
    "base_url_ema = \"https://api.polygon.io/v1/indicators/ema\"\n",
    "\n",
    "# Define ticker and date range\n",
    "ticker = \"NTNX\"\n",
    "start_date = \"2023-01-01\"\n",
    "end_date = \"2023-12-31\"\n",
    "\n",
    "# Convert date strings to datetime objects\n",
    "start = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "end = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "\n",
    "# Initialize an empty list to hold all stock data\n",
    "all_stock_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch open/close data for a specific ticker and date\n",
    "def fetch_stock_data(ticker, date):\n",
    "    url = f\"{base_url_open_close}/{ticker}/{date}\"\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if data.get(\"status\") == \"OK\":\n",
    "            stock_data = {\n",
    "                \"Symbol\": data.get(\"symbol\"),\n",
    "                \"Date\": data.get(\"from\"),\n",
    "                \"Close\": data.get(\"close\"),\n",
    "                \"Open\": data.get(\"open\"),\n",
    "                \"High\": data.get(\"high\"),\n",
    "                \"Low\": data.get(\"low\"),\n",
    "                \"Volume\": data.get(\"volume\")\n",
    "            }\n",
    "            return stock_data\n",
    "        else:\n",
    "            print(f\"No trading data for {ticker} on {date}.\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Failed to fetch data for {ticker} on {date}: {response.status_code}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch EMA data for a specific window\n",
    "def fetch_ema(ticker, window):\n",
    "    url = f\"{base_url_ema}/{ticker}?timespan=day&adjusted=true&window={window}&series_type=close&order=desc&apiKey={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if data.get(\"status\") == \"OK\":\n",
    "            ema_values = data.get(\"values\", [])\n",
    "            ema_data = {entry['timestamp']: entry['value'] for entry in ema_values}\n",
    "            return ema_data\n",
    "        else:\n",
    "            print(f\"No EMA data for {ticker} with window {window}.\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Failed to fetch EMA data for {ticker} with window {window}: {response.status_code}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch EMA20 and EMA50 for the date range\n",
    "ema20_data = fetch_ema(ticker, 20)\n",
    "ema50_data = fetch_ema(ticker, 50)\n",
    "\n",
    "# Loop over each date in the range\n",
    "current_date = start\n",
    "api_call_count = 0\n",
    "\n",
    "while current_date <= end:\n",
    "    date_str = current_date.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    # Fetch stock data for the current date\n",
    "    stock_data = fetch_stock_data(ticker, date_str)\n",
    "    \n",
    "    if stock_data:\n",
    "        timestamp = int(datetime.strptime(date_str, \"%Y-%m-%d\").timestamp()) * 1000  # Convert to milliseconds\n",
    "        # Add EMA values for this date if available\n",
    "        stock_data[\"ema20\"] = ema20_data.get(timestamp) if ema20_data else None\n",
    "        stock_data[\"ema50\"] = ema50_data.get(timestamp) if ema50_data else None\n",
    "        all_stock_data.append(stock_data)\n",
    "\n",
    "    # Increment API call count\n",
    "    api_call_count += 1\n",
    "\n",
    "    # After every 5 API calls, pause for 1 minute to respect the API limit\n",
    "    if api_call_count == 5:\n",
    "        print(\"Pausing for 1 minute to respect API rate limit...\")\n",
    "        time.sleep(60)\n",
    "        api_call_count = 0\n",
    "\n",
    "    # Move to the next date\n",
    "    current_date += timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the collected data\n",
    "df = pd.DataFrame(all_stock_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output path for the CSV file\n",
    "output_path = r\"C:\\Users\\SamuliMustonen\\Documents\\Ready Solutions\\Docs\\StockTrading\\Data\\stock_data.csv\"\n",
    "\n",
    "# Append the DataFrame to the existing CSV file\n",
    "df.to_csv(output_path, mode='a', index=False, header=False)\n",
    "\n",
    "print(f\"Data has been appended to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
