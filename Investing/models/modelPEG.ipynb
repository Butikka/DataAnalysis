{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "# from datetime import datetime, timedelta, date\n",
    "from datetime import datetime\n",
    "import time\n",
    "from polygon import RESTClient\n",
    "import logging\n",
    "import signal\n",
    "import sys\n",
    "import pickle\n",
    "import lz4.frame  # type: ignore\n",
    "import concurrent.futures\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import nbimporter\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the saved .pickle.gz file\n",
    "file_path = \"C:\\\\Users\\\\SamuliMustonen\\\\Documents\\\\Ready Solutions\\\\Docs\\\\StockTrading\\\\Data\\\\rawComplete\\\\all_raw_data_2022-01-01_to_2024-09-30.pickle.gz\"\n",
    "\n",
    "# Load the DataFrame from the compressed pickle file\n",
    "try:\n",
    "    df = pd.read_pickle(file_path, compression='gzip')\n",
    "    print(\"File loaded successfully!\")\n",
    "    print(df.head())  # Display the first few rows\n",
    "except Exception as e:\n",
    "    print(f\"Error loading file: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the dataset\n",
    "missing_data = df.isnull().sum()\n",
    "print(missing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary statistics\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all unique symbols in the 'symbol' column\n",
    "unique_symbols = df['symbol'].unique()\n",
    "print(unique_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for a specific symbol and date range within 2023\n",
    "# symbol_filter = 'ABUS'  # Replace with the symbol you want to filter\n",
    "date_filter = (df['timestamp'] >= '2023-01-01') & (df['timestamp'] <= '2023-12-31')\n",
    "openHigher = (df['openHigher'] == 1)\n",
    "accVolume = (df['accVolume']==1)\n",
    "uptrend = (df['uptrend']==1)\n",
    "excCandle = (df['exceptionalCandleSize']==1)\n",
    "closeHigh = (df['closeHigh']==1)\n",
    "\n",
    "# Apply filters\n",
    "filtered_df = df[date_filter & openHigher & accVolume & uptrend & excCandle & closeHigh]\n",
    "# filtered_df = df[date_filter & openHigher & accVolume & uptrend & excCandle]\n",
    "\n",
    "# View the filtered DataFrame\n",
    "unique_symbols = filtered_df['symbol'].unique()\n",
    "unique_count_symbols = filtered_df['symbol'].nunique()\n",
    "print(unique_symbols)\n",
    "print(unique_count_symbols)\n",
    "# print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for a specific symbol and date range within 2023\n",
    "symbol_filter = 'AGL'  # Replace with the symbol you want to filter\n",
    "date_filter = (df['timestamp'] >= '2023-01-01') & (df['timestamp'] <= '2023-12-31')\n",
    "openHigher = (df['openHigher'] == 1)\n",
    "accVolume = (df['accVolume']==1)\n",
    "uptrend = (df['uptrend']==1)\n",
    "excCandle = (df['exceptionalCandleSize']==1)\n",
    "closeHigh = (df['closeHigh']==1)\n",
    "\n",
    "# Apply all filters at once\n",
    "filtered_df = df[\n",
    "    # (df['symbol'] == symbol_filter) & \n",
    "    date_filter & \n",
    "    openHigher & \n",
    "    accVolume & \n",
    "    uptrend & \n",
    "    excCandle &\n",
    "    closeHigh\n",
    "]\n",
    "\n",
    "# View the filtered DataFrame\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the alert list to csv.\n",
    "start_date = \"2023-01-01\"  \n",
    "end_date = \"2023-12-31\"    \n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')  # current timestamp\n",
    "\n",
    "save_path = \"C:\\\\Users\\\\SamuliMustonen\\\\Documents\\\\Ready Solutions\\\\Docs\\\\StockTrading\\\\Data\\\\modelPEG\"\n",
    "file_name = f\"model_PEG_alert_list_{start_date}_to_{end_date}_{timestamp}.csv\"\n",
    "full_path = f\"{save_path}\\\\{file_name}\"\n",
    "\n",
    "# Save the DataFrame to CSV\n",
    "filtered_df.to_csv(full_path, index=False)\n",
    "\n",
    "print(f\"File saved to: {full_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
